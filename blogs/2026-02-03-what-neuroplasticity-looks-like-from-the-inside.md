---
title: "What Neuroplasticity Looks Like From the Inside"
subtitle: "A field journal from the intersection of synesthesia, code, and computational neuroscience"
date_posted: "2026-02-03"
source: "https://medium.com/@qikevinl"
tags: ["#Neuroscience", "#Synesthesia", "#Neuroplasticity", "#BrainComputerInterface", "#QIF", "#FieldJournal"]
---

# What Neuroplasticity Looks Like From the Inside

### *A field journal from the intersection of synesthesia, code, and computational neuroscience*

· · ·

I cried for the first time in a long time last night. Not from sadness — from clarity.

I'd been working through the QIF framework — equations, whitepaper, neuroethics, all of it — and for the first time, every piece connected. Not abstractly. I mean I could *see* the path. The whitepaper, the ethics questions, the framework architecture — they stopped being separate tasks and became one thing.

The moment they unified, the emotional dam broke.

But that's not what this post is about. Something stranger happened afterward.

· · ·

## My Synesthesia Changed

I have synesthesia — the neurological phenomenon where senses cross-wire. For me, it manifests as geometry and spatial relationships tied to abstract concepts. Numbers have shapes. Mathematical relationships have colors. Logical structures occupy physical space in my mind's eye.

Last night I noticed something: **my synesthetic mappings are shifting**.

The more I build visualizations to explain math to myself — 3D representations, interactive diagrams, code-generated figures — the more my internal perceptual mappings rearrange. Colors and geometry in my mind's vector space are reorganizing to match the problems I'm working on.

This only happens during deep focus and meditation. Not casual thinking. It requires a specific state — something like sustained, deliberate attention combined with creative problem-solving.

· · ·

## The Feedback Loop

Here's my best attempt at explaining what's happening:

The act of creating external visual representations of abstract math is feeding back into my internal perceptual system. My synesthesia isn't static — it's **adaptive**. Building visualizations-as-code isn't just producing output for others; it's retraining my own neural mappings.

```
Abstract concept
    ↓
Write code to visualize it
    ↓
See the external representation
    ↓
Internal synesthetic mapping updates
    ↓
New spatial intuition for the concept
    ↓
Deeper understanding → new abstractions
    ↓
(loop)
```

The external tool (code → visualization) is becoming an extension of the internal tool (synesthesia → spatial reasoning). The code isn't separate from the cognition — it's part of the cognitive loop.

**This might be what neuroplasticity looks like from the inside when you're paying attention.**

· · ·

## Why This Matters Beyond My Head

This connects to the QIF research in ways I didn't expect:

**Measurable coherence shifts.** If synesthetic mappings can shift in real time, they represent a measurable change in neural signal patterns. What would the coherence metric (Cₛ) look like during these transitions? If we could measure it, we'd have direct evidence that internal perceptual reorganization changes the signal characteristics a BCI would read.

**State-dependent plasticity.** The fact that this only happens during deep focus + meditation suggests a specific brain state — possibly high coherence, specific band activity — enables rapid perceptual retraining. That state is a measurable condition. It has an EEG signature. It means plasticity isn't always on — it's gated.

**Neurodivergence as a research window.** Synesthesia + hyperfocus might create a unique window where this kind of rapid perceptual retraining is possible. The same traits that make thoughts feel scattered in default mode may enable faster remapping in focus mode. If true, neurodivergent individuals aren't just research subjects — they're *instruments*. Our perceptual differences are data.

· · ·

## The Uncomfortable Implication

If external tools can reshape internal neural mappings this quickly and this noticeably — what happens when the external tool is a brain-computer interface?

A BCI reads neural signals. But if the act of reading changes the signals — if the measurement reshapes the system — then the interface isn't passive. It's part of the cognitive architecture. It's in the loop.

This is exactly what QIF's coherence framework models:

> **f × S ≈ k**

Increase the frequency of interaction (f) with a neural system, and the spatial extent of coherence (S) must change. The system can't remain unchanged under observation. This isn't just a quantum principle — it's an information-theoretic one. And I'm experiencing it firsthand with nothing more than code and a screen.

What happens when the interaction frequency is a thousand electrodes reading a million neurons in real time?

· · ·

## A Field Journal, Not a Paper

I started keeping what I'm calling a **Field Journal** — real-time observations about my own cognition during this research. Not polished. Not retroactive. Just: *did my brain do something I didn't expect?*

The rule is simple: write when something surprises you about your own mind.

| Signal | Example |
|--------|---------|
| **Perceptual shift** | "My synesthesia for X changed after doing Y" |
| **Unexpected connection** | "While working on tunneling math, I suddenly saw why Z looks the way it does" |
| **Focus state change** | "Deep meditation shifted how I spatially reason about vectors" |
| **The weird dismissed thing** | "I noticed X but almost ignored it. Writing it down anyway." |
| **Frustration with translation** | "I can see it but I can't say it — here's my best attempt" |

The dismissed observations are often the most valuable entries months later. Science has a long history of dismissing subjective experience as irrelevant data. But if the subject *is* the instrument — as in synesthesia research, BCI calibration, and neural signal analysis — then first-person observation isn't noise. It's signal.

· · ·

## What I'm Asking

If you're a **neuroscientist**: Has anyone measured EEG coherence changes during synesthetic remapping? Is there a known signature for "plasticity mode" — the state where perceptual mappings become malleable?

If you're a **BCI researcher**: Do you see signal pattern shifts when subjects learn to control an interface? How fast do those shifts happen? Is there a coherence signature for the transition?

If you're a **synesthete**: Have you noticed your mappings change based on what you're working on? Do specific mental states make the shifts more pronounced?

If you're a **meditation researcher**: Is there overlap between the focus states that enable this kind of perceptual shift and the states measured in long-term meditators? What bands dominate?

I don't have answers yet. I have one data point — myself — and a framework that predicts this kind of thing should happen. That's not science. It's the beginning of a question.

But good science starts with someone saying: *that's weird. Let me write it down.*

· · ·

*This post is adapted from the [QIF Field Journal](https://github.com/qinnovates/mindloft/blob/main/neurosecurity/qif/QIF-FIELD-JOURNAL.md) — a living, append-only research journal maintained alongside the QIF framework.*

*Part of the [QIF (Quantum Indeterministic Framework for Neural Security)](https://github.com/qinnovates/mindloft/) research.*

**Sub-Tags:** #Synesthesia #Neuroplasticity #BCI #Neuroscience #QIF #FieldJournal #Coherence #Neurodivergence #Meditation #BrainComputerInterface

---

*Follow my work and research. Collaborate and contribute on [GitHub](https://github.com/qinnovates/mindloft/).*
